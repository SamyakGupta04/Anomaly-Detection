{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs-6tT3yBZp8",
        "outputId": "c73a310a-6a70-4d52-d211-2350164b8b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /walmart/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs('/walmart/drive', exist_ok=True)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/walmart/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# ML Imports\n",
        "# ============================\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================\n",
        "# Folder setup inside your Drive\n",
        "# ============================\n",
        "\n",
        "# Base path to your project folder in Google Drive\n",
        "base_path = \"/walmart/drive/My Drive/walmart\"\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "# Folder creation helper\n",
        "def folder(f_name):\n",
        "    \"\"\"Creates a folder if it doesn't exist.\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(f_name):\n",
        "            os.makedirs(f_name)\n",
        "    except OSError:\n",
        "        print(\"The folder could not be created!\")\n",
        "\n",
        "# Create results folders\n",
        "results_path = os.path.join(base_path, \"results\")\n",
        "graphs_path = os.path.join(results_path, \"result_graph_Final\")\n",
        "\n",
        "folder(results_path)\n",
        "folder(graphs_path)\n",
        "\n",
        "# ============================\n",
        "# File paths\n",
        "# ============================\n",
        "csv_files = [\"all_data.csv\"]  # dataset file name\n",
        "path = base_path + \"/\"        # dataset directory\n",
        "result = os.path.join(results_path, \"results_Final.csv\")\n",
        "\n",
        "# ============================\n",
        "# Feature selection\n",
        "# ============================\n",
        "usecols = [\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
        "           \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\", \"Flow Duration\", \"Bwd Packet Length Max\",\n",
        "           \"Flow IAT Max\", \"Flow IAT Mean\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Min\",\n",
        "           \"Bwd Packet Length Mean\", \"Flow Packets/s\", \"Fwd Packet Length Mean\", \"Total Backward Packets\",\n",
        "           \"Total Fwd Packets\", \"Fwd Packet Length Max\", \"Bwd Packet Length Min\", 'Label']\n",
        "\n",
        "# ============================\n",
        "# ML algorithms\n",
        "# ============================\n",
        "ml_list = {\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"QDA\": QDA(),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(13, 13, 13), max_iter=500),\n",
        "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    \"ID3\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\"),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(3)\n",
        "}\n",
        "\n",
        "# Features for some models\n",
        "others = [\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
        "          \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\"]\n",
        "\n",
        "# Algorithm-specific feature sets\n",
        "algorithms_features = {\n",
        "    \"Naive Bayes\": ['Bwd Packet Length Std', 'Total Length of Fwd Packets', 'Flow IAT Min',\n",
        "                    'Fwd Packet Length Min', 'Flow Packets/s', 'Fwd Packet Length Mean'],\n",
        "    \"QDA\": ['Bwd Packet Length Std', 'Flow Bytes/s', 'Total Length of Fwd Packets', 'Flow IAT Min'],\n",
        "    \"MLP\": ['Bwd Packet Length Std', 'Flow Bytes/s', 'Total Length of Fwd Packets', 'Fwd Packet Length Std',\n",
        "            'Flow IAT Min', 'Bwd Packet Length Max', 'Fwd Packet Length Min', 'Bwd Packet Length Mean',\n",
        "            'Total Backward Packets', 'Total Fwd Packets', 'Fwd Packet Length Max', 'Bwd Packet Length Min'],\n",
        "    \"Random Forest\": others,\n",
        "    \"ID3\": others,\n",
        "    \"AdaBoost\": others,\n",
        "    \"Nearest Neighbors\": others\n",
        "}\n",
        "\n",
        "# ============================\n",
        "# Processing start\n",
        "# ============================\n",
        "seconds = time.time()\n",
        "\n",
        "# Create CSV result file\n",
        "with open(result, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    wrt = csv.writer(f)\n",
        "    wrt.writerow([\"File\", \"ML algorithm\", \"Sample Predictions\"])\n",
        "\n",
        "# ============================\n",
        "# Loop through datasets\n",
        "# ============================\n",
        "for j in csv_files:\n",
        "    print('%-17s %-17s' % (\"File\", \"ML algorithm\"))\n",
        "    df = pd.read_csv(path + j, usecols=usecols)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # Convert labels to numeric: BENIGN → 1, others → 0\n",
        "    df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x == \"BENIGN\" else 0)\n",
        "\n",
        "    y = df[\"Label\"]\n",
        "    X_full = df.drop(columns=[\"Label\"])\n",
        "\n",
        "    # Loop through algorithms\n",
        "    for algo_name, algo_model in ml_list.items():\n",
        "        X = X_full[algorithms_features[algo_name]]\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.20, random_state=42\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        clf = algo_model\n",
        "        clf.fit(X_train, y_train)\n",
        "        predictions = clf.predict(X_test)\n",
        "\n",
        "        # Show first 50 predictions\n",
        "        sample_preds = list(predictions[:50])\n",
        "        print(f\"\\nFile: {j[:-4]} | Algorithm: {algo_name}\")\n",
        "        print(\"Sample Predictions (first 50):\", sample_preds)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Save results to CSV\n",
        "        with open(result, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            wrt = csv.writer(f)\n",
        "            wrt.writerow([j[:-4], algo_name, sample_preds])\n",
        "\n",
        "print(\"\\nMission accomplished!\")\n",
        "print(\"Total operation time:\", round(time.time() - seconds, 2), \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AlrwXrMBhAq",
        "outputId": "c94cdebe-c628-4474-bff3-146e1daa19e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File              ML algorithm     \n",
            "\n",
            "File: all_data | Algorithm: Naive Bayes\n",
            "Sample Predictions (first 50): [np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "File: all_data | Algorithm: QDA\n",
            "Sample Predictions (first 50): [np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1)]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, os\n",
        "\n",
        "results_path = '/walmart/drive/My Drive/walmart/results/'\n",
        "models = {}\n",
        "\n",
        "for file in os.listdir(results_path):\n",
        "    if file.endswith('.pkl'):\n",
        "        model_name = file.replace('_model.pkl', '')\n",
        "        models[model_name] = joblib.load(os.path.join(results_path, file))\n",
        "\n",
        "print(\"Loaded models:\", list(models.keys()))\n"
      ],
      "metadata": {
        "id": "8DQxmECbOMg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"Random Forest\"].predict(X_new)\n"
      ],
      "metadata": {
        "id": "DMsSFt1pOQBJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}